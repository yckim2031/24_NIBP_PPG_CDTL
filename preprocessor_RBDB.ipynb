{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc41a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from sklearn import preprocessing\n",
    "from scipy.signal import cheby2, freqz, filtfilt\n",
    "from scipy.signal import decimate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41de8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "def Nan_interpolation(input_sig):\n",
    "    nan_indices = np.isnan(input_sig)\n",
    "    non_nan_indices = np.arange(len(input_sig))[~nan_indices]\n",
    "    \n",
    "    input_sig[nan_indices] = np.interp(np.where(nan_indices)[0], non_nan_indices, input_sig[non_nan_indices])\n",
    "    \n",
    "    return input_sig\n",
    "\n",
    "#FIR BPF\n",
    "def BPFilter(input_sig, lowcut=0.5, highcut=5.0, numtaps = 1001, window = 'hamming'):\n",
    "    # Define filter parameters\n",
    "    fs = 125 # Sampling frequency (Hz)\n",
    "    nyquist = 0.5 * fs # Nyquist frequency\n",
    "    bands = [lowcut/nyquist, highcut/nyquist]\n",
    "\n",
    "    # Design the ppg FIR filter\n",
    "    fir_coeff = signal.firwin(numtaps, bands, window = window, pass_zero = 'bandpass')\n",
    "\n",
    "    # Apply the filter to the PPG signal\n",
    "    filtered_sig = signal.lfilter(fir_coeff, 1.0, input_sig)[int((numtaps-1)/2):] #Filter delay\n",
    "    \n",
    "    return filtered_sig\n",
    "\n",
    "def MAFilter(input_sig, window_size):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    smoothed_signal = np.convolve(input_sig, window, mode='same')\n",
    "    return smoothed_signal\n",
    "\n",
    "def SAI_Algorithm(input_sig):\n",
    "    # 1. Beat detection\n",
    "    peaks_indx, _ = signal.find_peaks(input_sig, distance = 60)\n",
    "    valleys_indx = np.array([], dtype=np.int64)\n",
    "    valleys_indx = np.append(valleys_indx, [np.argmin(input_sig[peaks_indx[i]: peaks_indx[i + 1]]) + peaks_indx[i] for i in range(len(peaks_indx) - 1)])\n",
    "    \n",
    "    # 3. Abnormality criterion\n",
    "    Ps_c = 180\n",
    "    Pd_c = 20\n",
    "    Pm_min_c, Pm_max_c = 30, 200\n",
    "    f_min_c, f_max_c = 20, 200\n",
    "    Pp_c = 20\n",
    "    T = 2 #second\n",
    "    dPs_c = 20\n",
    "    dPd_c = 20\n",
    "    dT_c = 2/3\n",
    "    \n",
    "    bp_ft_Ps = input_sig[peaks_indx[2:-1]]\n",
    "    bp_ft_Pd = input_sig[valleys_indx[2:]]\n",
    "    bp_ft_Pp = bp_ft_Ps - bp_ft_Pd\n",
    "    bp_ft_Pm = (bp_ft_Ps + bp_ft_Pd) / 3\n",
    "    bp_ft_T = (valleys_indx[2:] - valleys_indx[1:-1]) / 125\n",
    "    bp_ft_f = 60 / bp_ft_T\n",
    "    \n",
    "    dPs = np.abs(bp_ft_Ps - input_sig[peaks_indx[1:-2]])\n",
    "    dPd = np.abs(bp_ft_Pd - input_sig[valleys_indx[1:-1]])\n",
    "    dT = np.abs(bp_ft_T - (valleys_indx[1:-1] - valleys_indx[:-2]) / 125)\n",
    "    \n",
    "    mask = (\n",
    "        (bp_ft_Ps > Ps_c) |\n",
    "        (bp_ft_Ps < 80) |\n",
    "        (bp_ft_Pd < Pd_c) |\n",
    "        (bp_ft_Pm < Pm_min_c) | (bp_ft_Pm > Pm_max_c) |\n",
    "        (bp_ft_Pp < Pp_c) |\n",
    "        (bp_ft_f < f_min_c) | (bp_ft_f > f_max_c) |\n",
    "        (dPs > dPs_c) |\n",
    "        (dPd > dPd_c) |\n",
    "        (dT > dT_c) |\n",
    "        (bp_ft_T > T)\n",
    "    )\n",
    "    \n",
    "    corrupted_indx = valleys_indx[2:][mask]\n",
    "            \n",
    "    return corrupted_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30004dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_RBDB_11.npz successfully processed, ppg data size:  (124, 125) (124, 125) blood pressure size:  (124, 2)\n",
      "raw_RBDB_12.npz successfully processed, ppg data size:  (56, 125) (56, 125) blood pressure size:  (56, 2)\n",
      "raw_RBDB_13.npz successfully processed, ppg data size:  (187, 125) (187, 125) blood pressure size:  (187, 2)\n",
      "raw_RBDB_14.npz successfully processed, ppg data size:  (185, 125) (185, 125) blood pressure size:  (185, 2)\n",
      "raw_RBDB_15.npz successfully processed, ppg data size:  (116, 125) (116, 125) blood pressure size:  (116, 2)\n",
      "raw_RBDB_16.npz successfully processed, ppg data size:  (421, 125) (421, 125) blood pressure size:  (421, 2)\n",
      "raw_RBDB_17.npz successfully processed, ppg data size:  (224, 125) (224, 125) blood pressure size:  (224, 2)\n",
      "raw_RBDB_18.npz successfully processed, ppg data size:  (65, 125) (65, 125) blood pressure size:  (65, 2)\n",
      "raw_RBDB_19.npz successfully processed, ppg data size:  (82, 125) (82, 125) blood pressure size:  (82, 2)\n",
      "raw_RBDB_1_.npz successfully processed, ppg data size:  (26, 125) (26, 125) blood pressure size:  (26, 2)\n",
      "raw_RBDB_21.npz successfully processed, ppg data size:  (141, 125) (141, 125) blood pressure size:  (141, 2)\n",
      "raw_RBDB_22.npz successfully processed, ppg data size:  (134, 125) (134, 125) blood pressure size:  (134, 2)\n",
      "raw_RBDB_23.npz successfully processed, ppg data size:  (272, 125) (272, 125) blood pressure size:  (272, 2)\n",
      "raw_RBDB_24.npz successfully processed, ppg data size:  (85, 125) (85, 125) blood pressure size:  (85, 2)\n",
      "raw_RBDB_2_.npz successfully processed, ppg data size:  (103, 125) (103, 125) blood pressure size:  (103, 2)\n",
      "raw_RBDB_3_.npz successfully processed, ppg data size:  (99, 125) (99, 125) blood pressure size:  (99, 2)\n",
      "raw_RBDB_4_.npz successfully processed, ppg data size:  (2, 125) (2, 125) blood pressure size:  (2, 2)\n",
      "raw_RBDB_6_.npz successfully processed, ppg data size:  (409, 125) (409, 125) blood pressure size:  (409, 2)\n",
      "raw_RBDB_7_.npz successfully processed, ppg data size:  (202, 125) (202, 125) blood pressure size:  (202, 2)\n",
      "raw_RBDB_8_.npz successfully processed, ppg data size:  (203, 125) (203, 125) blood pressure size:  (203, 2)\n",
      "raw_RBDB_9_.npz successfully processed, ppg data size:  (101, 125) (101, 125) blood pressure size:  (101, 2)\n"
     ]
    }
   ],
   "source": [
    "#Loop preprocessing CST Processing\n",
    "\n",
    "raw_data_dir = \"F:\\\\Lab\\\\Research\\\\NIBP_PPG\\\\Dataset\\\\Ex_3\\\\RU_dataset\\\\CST_Raw\"\n",
    "down_folder_dir = \"F:\\\\Lab\\\\Research\\\\NIBP_PPG\\\\Dataset\\\\Ex_3\\\\RU_dataset\\\\CST_Processed\"\n",
    "file_list = os.listdir(raw_data_dir)\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.npz'):\n",
    "\n",
    "        Data = np.load(raw_data_dir+\"\\\\\"+file_name)\n",
    "        ppg1_raw_sig = Data['x1']\n",
    "        ppg2_raw_sig = Data['x2']\n",
    "        bp_raw_sig = Data['y']\n",
    "\n",
    "        #Nan 제거\n",
    "        ppg1_raw_sig = Nan_interpolation(ppg1_raw_sig)\n",
    "        ppg2_raw_sig = Nan_interpolation(ppg2_raw_sig)\n",
    "        bp_raw_sig = Nan_interpolation(bp_raw_sig)\n",
    "\n",
    "        #Lag compensation using Cross Correlation function\n",
    "        ppg1_fp = ppg1_raw_sig[0:250]\n",
    "        ppg1_fp = (ppg1_fp-np.mean(ppg1_fp))/np.std(ppg1_fp)\n",
    "        bp_fp = bp_raw_sig[0:250]\n",
    "        bp_fp = (bp_fp-np.mean(bp_fp))/np.std(bp_fp)\n",
    "        correlation = np.correlate(ppg1_fp, bp_fp, mode='same')\n",
    "        max_indx = signal.find_peaks(correlation[125:])\n",
    "        ppg1_sig_lc = ppg1_raw_sig[max_indx[0][0]:]\n",
    "        ppg2_sig_lc = ppg2_raw_sig[max_indx[0][0]:]\n",
    "        bp_raw_sig = bp_raw_sig[:-max_indx[0][0]]\n",
    "\n",
    "        #Frequency filter\n",
    "        # FIR Filter 사용\n",
    "        numtaps = 1001\n",
    "        ppg1_sig_lc = BPFilter(ppg1_sig_lc, numtaps = numtaps, window = 'hamming')\n",
    "        ppg2_sig_lc = BPFilter(ppg2_sig_lc, numtaps = numtaps, window = 'hamming')\n",
    "        \"\"\"ppg1_sig_lc = ppg1_sig_lc[(numtaps-1)//2:]\n",
    "        ppg2_sig_lc = ppg2_sig_lc[(numtaps-1)//2:]\"\"\"\n",
    "        bp_MAF_sig = MAFilter(bp_raw_sig, 10)[(numtaps-1)//2:]\n",
    "        \n",
    "        #신호 길이 맞춰주기\n",
    "        gap = ppg1_sig_lc.shape[0] - bp_MAF_sig.shape[0]\n",
    "        if gap < 0:\n",
    "            bp_MAF_sig = bp_MAF_sig[:ppg1_sig_lc.shape[0]]\n",
    "        if gap > 0:\n",
    "            ppg1_sig_lc = ppg1_sig_lc[:bp_MAF_sig.shape[0]]\n",
    "            ppg2_sig_lc = ppg2_sig_lc[:bp_MAF_sig.shape[0]]\n",
    "\n",
    "        #Downsample to 25Hz\n",
    "        ori_rate = 125\n",
    "        targ_rate = 25\n",
    "        decimation_factor = int(ori_rate / targ_rate)\n",
    "        ppg1_sig = decimate(ppg1_sig_lc, decimation_factor, zero_phase=True)\n",
    "        ppg2_sig = decimate(ppg2_sig_lc, decimation_factor, zero_phase=True)\n",
    "\n",
    "        #5초간 윈도우\n",
    "        indx_num_ppg = 5 * 25\n",
    "        num_chunks_ppg = ppg1_sig.shape[0] // indx_num_ppg\n",
    "\n",
    "        indx_num_bp = 5 * 125\n",
    "        num_chunks_bp = bp_MAF_sig.shape[0] // indx_num_bp\n",
    "\n",
    "        ppg1_data = ppg1_sig[:num_chunks_ppg * indx_num_ppg].reshape(num_chunks_ppg, indx_num_ppg)\n",
    "        ppg2_data = ppg2_sig[:num_chunks_ppg * indx_num_ppg].reshape(num_chunks_ppg, indx_num_ppg)\n",
    "        bp_data = bp_MAF_sig[:num_chunks_bp * indx_num_bp].reshape(num_chunks_bp, indx_num_bp)\n",
    "\n",
    "        #Normalization\n",
    "        ppg1_data_mean = np.mean(ppg1_data, axis=1, keepdims=True)\n",
    "        ppg1_data_std = np.std(ppg1_data, axis=1, keepdims=True)\n",
    "        ppg1_data = (ppg1_data - ppg1_data_mean) / ppg1_data_std\n",
    "        \n",
    "        ppg2_data_mean = np.mean(ppg2_data, axis=1, keepdims=True)\n",
    "        ppg2_data_std = np.std(ppg2_data, axis=1, keepdims=True)\n",
    "        ppg2_data = (ppg2_data - ppg2_data_mean) / ppg2_data_std\n",
    "\n",
    "        #Auto-correlation - ppg_corrupted_sig - Auto-correlation 값으로 줄세워서 가장 주기성 높은 애들로만 7200개 모으기\n",
    "        #auto_correlation 배열에 두번째 correlation peak 값 저장\n",
    "        ppg1_data_corrupted_indx = np.empty((0,), dtype=int)\n",
    "        auto_correlation = np.empty((0,))\n",
    "\n",
    "        for i in range(ppg1_data.shape[0]):\n",
    "            auto_correlation_array = np.correlate(ppg1_data[i],ppg1_data[i],mode='same')\n",
    "            auto_correlation_array = auto_correlation_array/np.max(auto_correlation_array)\n",
    "            temp_peaks = signal.find_peaks(auto_correlation_array, height=0.7)\n",
    "\n",
    "            if temp_peaks[0].shape[0] < 3 or temp_peaks[0].shape[0] > 5:\n",
    "                ppg1_data_corrupted_indx = np.append(ppg1_data_corrupted_indx, i)\n",
    "                auto_correlation = np.append(auto_correlation,0)\n",
    "            else:\n",
    "                sec_peak_indx = temp_peaks[0][temp_peaks[0].shape[0]//2+1]\n",
    "                auto_correlation = np.append(auto_correlation, auto_correlation_array[sec_peak_indx])\n",
    "\n",
    "        #BP SAI corrupted signal filter\n",
    "        bp_corrupted_indx = SAI_Algorithm(bp_MAF_sig)\n",
    "\n",
    "        bp_data_corrupted_indx = np.empty((0,), dtype = int)\n",
    "        for i in range(bp_data.shape[0]):\n",
    "            ispeak, _ = signal.find_peaks(bp_data[i], distance = 60)\n",
    "            if len(ispeak) <= 2 or len(ispeak) >=10:\n",
    "                bp_data_corrupted_indx = np.append(bp_data_corrupted_indx, i)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                for k in range(bp_corrupted_indx.shape[0]):\n",
    "                    if bp_corrupted_indx[k]>625*i and bp_corrupted_indx[k]<625*(i+1):\n",
    "                        bp_data_corrupted_indx = np.append(bp_data_corrupted_indx, i)\n",
    "                        break\n",
    "\n",
    "        corrupted_data_indx = np.concatenate((ppg1_data_corrupted_indx, bp_data_corrupted_indx))\n",
    "        corrupted_data_indx = np.unique(corrupted_data_indx)\n",
    "\n",
    "        ppg1_data = np.delete(ppg1_data, corrupted_data_indx, axis=0)\n",
    "        ppg2_data = np.delete(ppg2_data, corrupted_data_indx, axis=0)\n",
    "        bp_data = np.delete(bp_data, corrupted_data_indx, axis=0)\n",
    "        auto_correlation = np.delete(auto_correlation, corrupted_data_indx, axis=0)\n",
    "        auto_correlation_indx = np.argsort(auto_correlation)[::-1]\n",
    "\n",
    "        #Sort according to correlation value index\n",
    "        ppg1_data = ppg1_data[auto_correlation_indx]\n",
    "        ppg2_data = ppg2_data[auto_correlation_indx]\n",
    "        bp_data = bp_data[auto_correlation_indx]\n",
    "\n",
    "        #Calculate mean of blood pressures\n",
    "        bp_data_label = np.empty((0,2))\n",
    "        for i in range(bp_data.shape[0]):\n",
    "            peaks_temp,_ = signal.find_peaks(bp_data[i], distance = 60)\n",
    "            valleys_temp = np.empty((0,),dtype=int)\n",
    "            valleys_temp = np.append(valleys_temp, [np.argmin(bp_data[i, peaks_temp[k]: peaks_temp[k + 1]]) + peaks_temp[k] for k in range(len(peaks_temp) - 1)])\n",
    "            peaks_mean = np.mean(bp_data[i,peaks_temp])\n",
    "            valleys_mean = np.mean(bp_data[i, valleys_temp])\n",
    "            bp_data_label = np.insert(bp_data_label, bp_data_label.shape[0], [peaks_mean, valleys_mean], axis=0)\n",
    "\n",
    "        #처리한 데이터 저장\n",
    "        print(file_name+\" successfully processed, ppg data size: \", ppg1_data.shape, ppg2_data.shape, 'blood pressure size: ', bp_data_label.shape)\n",
    "        npz_filename = \"processed_\"+file_name[4:]\n",
    "        np.savez(down_folder_dir+\"\\\\\"+npz_filename, x1=ppg1_data, x2=ppg2_data, y=bp_data_label)\n",
    "\n",
    "        \"\"\"gap = ppg1_data.shape[0]-bp_data_label.shape[0]\n",
    "\n",
    "        if gap < 0:\n",
    "            np.savez(down_folder_dir+\"\\\\\"+npz_filename, x1=ppg1_data[:ppg1_data.shape[0]], x2=ppg2_data[:ppg1_data.shape[0]], y=bp_data_label[:ppg1_data.shape[0]])\n",
    "        if gap > 0:\n",
    "            np.savez(down_folder_dir+\"\\\\\"+npz_filename, x1=ppg1_data[:bp_data_label.shape[0]], x2=ppg2_data[:bp_data_label.shape[0]], y=bp_data_label[:bp_data_label.shape[0]])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d6d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
